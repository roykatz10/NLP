{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd164902",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-06-11T16:56:09.394852Z",
     "iopub.status.busy": "2024-06-11T16:56:09.394526Z",
     "iopub.status.idle": "2024-06-11T16:56:13.888306Z",
     "shell.execute_reply": "2024-06-11T16:56:13.887222Z"
    },
    "papermill": {
     "duration": 4.506466,
     "end_time": "2024-06-11T16:56:13.890527",
     "exception": false,
     "start_time": "2024-06-11T16:56:09.384061",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 GPU(s) available.\n",
      "We will use the GPU: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "import torch\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():\n",
    "\n",
    "    # Tell PyTorch to use the GPU.\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58914954",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T16:56:13.909783Z",
     "iopub.status.busy": "2024-06-11T16:56:13.909376Z",
     "iopub.status.idle": "2024-06-11T16:56:41.154201Z",
     "shell.execute_reply": "2024-06-11T16:56:41.153223Z"
    },
    "papermill": {
     "duration": 27.25691,
     "end_time": "2024-06-11T16:56:41.156584",
     "exception": false,
     "start_time": "2024-06-11T16:56:13.899674",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.41.2)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.23.2)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\r\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2024.3.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.9.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\r\n",
      "Collecting sentence-transformers\r\n",
      "  Downloading sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\r\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.41.2)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.4)\r\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.1.2)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.26.4)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.11.4)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.23.2)\r\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (9.5.0)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.3.1)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (21.3)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.32.3)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.9.0)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.12.1)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2023.12.25)\r\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.15.1->sentence-transformers) (3.1.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\r\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\r\n",
      "Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: sentence-transformers\r\n",
      "Successfully installed sentence-transformers-3.0.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e41d8e08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T16:56:41.178382Z",
     "iopub.status.busy": "2024-06-11T16:56:41.178073Z",
     "iopub.status.idle": "2024-06-11T16:56:47.311136Z",
     "shell.execute_reply": "2024-06-11T16:56:47.310303Z"
    },
    "papermill": {
     "duration": 6.146606,
     "end_time": "2024-06-11T16:56:47.313548",
     "exception": false,
     "start_time": "2024-06-11T16:56:41.166942",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c66e34b501f4b72b7cf70198deb7cba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2f246aaab814c938798bff3cf5c4383",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aabbd777595342fd9cdf2ee5b2810dd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer,AutoModel\n",
    "\n",
    "# Load the tokenizer.\n",
    "print('Loading tokenizer...')\n",
    "# todo\n",
    "model_name = 'google-t5/t5-small'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, do_lower_case=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57db30e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T16:56:47.336882Z",
     "iopub.status.busy": "2024-06-11T16:56:47.336505Z",
     "iopub.status.idle": "2024-06-11T16:56:48.627768Z",
     "shell.execute_reply": "2024-06-11T16:56:48.626906Z"
    },
    "papermill": {
     "duration": 1.305204,
     "end_time": "2024-06-11T16:56:48.629876",
     "exception": false,
     "start_time": "2024-06-11T16:56:47.324672",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9935\n",
      "3084\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"/kaggle/input/claimdecomp3/train_claims_quantemp.json\") as f:\n",
    "  train_data = json.load(f)\n",
    "\n",
    "print(len(train_data))\n",
    "\n",
    "with open(\"/kaggle/input/claimdecomp3/val_claims_quantemp.json\") as f:\n",
    "  val_data = json.load(f)\n",
    "print(len(val_data))\n",
    "val_data = val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd5a4c75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T16:56:48.652857Z",
     "iopub.status.busy": "2024-06-11T16:56:48.652576Z",
     "iopub.status.idle": "2024-06-11T16:56:50.610057Z",
     "shell.execute_reply": "2024-06-11T16:56:50.608982Z"
    },
    "papermill": {
     "duration": 1.971347,
     "end_time": "2024-06-11T16:56:50.612269",
     "exception": false,
     "start_time": "2024-06-11T16:56:48.640922",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9935\n",
      "3084\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"/kaggle/input/claimdecomp3/nli_llmclaimdecomp_input_train_reranktop7.json\") as f:\n",
    "  train_evidence_data = json.load(f)\n",
    "\n",
    "print(len(train_evidence_data))\n",
    "\n",
    "with open(\"/kaggle/input/claimdecomp3/nli_llmclaimdecomp_input_val_reranktop7.json\") as f:\n",
    "  val_evidence_data = json.load(f)\n",
    "print(len(val_evidence_data))\n",
    "val_evidence_data = val_evidence_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdd6145b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T16:56:50.636855Z",
     "iopub.status.busy": "2024-06-11T16:56:50.636564Z",
     "iopub.status.idle": "2024-06-11T16:56:51.778419Z",
     "shell.execute_reply": "2024-06-11T16:56:51.777635Z"
    },
    "papermill": {
     "duration": 1.156564,
     "end_time": "2024-06-11T16:56:51.780643",
     "exception": false,
     "start_time": "2024-06-11T16:56:50.624079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import re\n",
    "LE = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05c87324",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T16:56:51.805808Z",
     "iopub.status.busy": "2024-06-11T16:56:51.805519Z",
     "iopub.status.idle": "2024-06-11T16:56:51.811724Z",
     "shell.execute_reply": "2024-06-11T16:56:51.810867Z"
    },
    "papermill": {
     "duration": 0.020384,
     "end_time": "2024-06-11T16:56:51.813620",
     "exception": false,
     "start_time": "2024-06-11T16:56:51.793236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_labels = [fact[\"label\"] for fact in train_data]\n",
    "val_labels = [fact[\"label\"] for fact in val_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "436c3f00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T16:56:51.842892Z",
     "iopub.status.busy": "2024-06-11T16:56:51.842199Z",
     "iopub.status.idle": "2024-06-11T16:56:51.863018Z",
     "shell.execute_reply": "2024-06-11T16:56:51.861767Z"
    },
    "papermill": {
     "duration": 0.039257,
     "end_time": "2024-06-11T16:56:51.865881",
     "exception": false,
     "start_time": "2024-06-11T16:56:51.826624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_labels_final = LE.fit_transform(train_labels)\n",
    "val_labels_final = LE.transform(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb49855",
   "metadata": {
    "papermill": {
     "duration": 0.014911,
     "end_time": "2024-06-11T16:56:51.893759",
     "exception": false,
     "start_time": "2024-06-11T16:56:51.878848",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8383f3bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T16:56:51.917029Z",
     "iopub.status.busy": "2024-06-11T16:56:51.916710Z",
     "iopub.status.idle": "2024-06-11T16:56:51.922731Z",
     "shell.execute_reply": "2024-06-11T16:56:51.921855Z"
    },
    "papermill": {
     "duration": 0.020384,
     "end_time": "2024-06-11T16:56:51.925134",
     "exception": false,
     "start_time": "2024-06-11T16:56:51.904750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9935\n",
      "9935\n",
      "9935\n",
      "-----------------------\n",
      "3084\n",
      "3084\n",
      "3084\n"
     ]
    }
   ],
   "source": [
    "################################# change ####################################\n",
    "# import csv\n",
    "# #todo\n",
    "# with open('/kaggle/input/quantemp/top_20_train.csv', 'r', newline='', encoding='utf-8') as file:\n",
    "#     reader = csv.reader(file)\n",
    "#     train_features_final = [row for row in reader]\n",
    "\n",
    "# #todo\n",
    "# with open('/kaggle/input/quantemp/top_20_val.csv', 'r', newline='', encoding='utf-8') as file:\n",
    "#     reader = csv.reader(file)\n",
    "#     val_features_final = [row for row in reader]\n",
    "\n",
    "print(len(train_evidence_data))\n",
    "print(len(train_labels_final))\n",
    "print(len(train_data))\n",
    "print(\"-----------------------\")\n",
    "print(len(val_evidence_data))\n",
    "print(len(val_labels_final))\n",
    "print(len(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5eaf266",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T16:56:51.948067Z",
     "iopub.status.busy": "2024-06-11T16:56:51.947784Z",
     "iopub.status.idle": "2024-06-11T16:56:51.952542Z",
     "shell.execute_reply": "2024-06-11T16:56:51.951700Z"
    },
    "papermill": {
     "duration": 0.01842,
     "end_time": "2024-06-11T16:56:51.954571",
     "exception": false,
     "start_time": "2024-06-11T16:56:51.936151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "2\n",
      "Did Sitharaman say this about LED bulbs?\n"
     ]
    }
   ],
   "source": [
    "cur = train_evidence_data[0][0]\n",
    "print(type(cur))\n",
    "print(len(cur))\n",
    "print(cur['claim'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c02f607c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T16:56:51.978626Z",
     "iopub.status.busy": "2024-06-11T16:56:51.978116Z",
     "iopub.status.idle": "2024-06-11T16:58:04.287757Z",
     "shell.execute_reply": "2024-06-11T16:58:04.286739Z"
    },
    "papermill": {
     "duration": 72.324247,
     "end_time": "2024-06-11T16:58:04.290320",
     "exception": false,
     "start_time": "2024-06-11T16:56:51.966073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2699: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for index, claim_decomps in enumerate(train_evidence_data):\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    text_evidence = \"[Evidences]:\"\n",
    "    text_question = \"[Questions]:\"\n",
    "    decompositions = []\n",
    "    evidences = []\n",
    "    for claim_decomp in claim_decomps:\n",
    "        decompositions.append(claim_decomp['claim'])\n",
    "        evidences = evidences + (claim_decomp['evidence'])\n",
    "        \n",
    "    claim = train_data[index]['claim']\n",
    "    for evidence in evidences:\n",
    "      text_evidence += evidence + \". \"\n",
    "    \n",
    "    for decomposition in decompositions:\n",
    "      text_question += decomposition + \" \"\n",
    "    \n",
    "    result = \"[Claim]:\" + claim + text_question + text_evidence\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        result,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 256,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        truncation=True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "\n",
    "    # Add the encoded sentence to the list.\n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "\n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "# print('Original: ', train_features_final[0])\n",
    "# print('Token IDs:', input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508d2e47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T12:41:11.484370Z",
     "iopub.status.busy": "2024-06-11T12:41:11.484028Z",
     "iopub.status.idle": "2024-06-11T12:41:11.490011Z",
     "shell.execute_reply": "2024-06-11T12:41:11.489054Z",
     "shell.execute_reply.started": "2024-06-11T12:41:11.484343Z"
    },
    "papermill": {
     "duration": 0.011134,
     "end_time": "2024-06-11T16:58:04.313397",
     "exception": false,
     "start_time": "2024-06-11T16:58:04.302263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6e69ead",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T16:58:04.338087Z",
     "iopub.status.busy": "2024-06-11T16:58:04.337747Z",
     "iopub.status.idle": "2024-06-11T16:58:26.131844Z",
     "shell.execute_reply": "2024-06-11T16:58:26.130943Z"
    },
    "papermill": {
     "duration": 21.809215,
     "end_time": "2024-06-11T16:58:26.134103",
     "exception": false,
     "start_time": "2024-06-11T16:58:04.324888",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original claim Amit Shah said Narendra Modi sleeps for 24 hours for the welfare of the poor.\n"
     ]
    }
   ],
   "source": [
    "val_input_ids = []\n",
    "val_attention_masks = []\n",
    "for index, claim_decomps in enumerate(val_evidence_data):    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    text_evidence = \"[Evidences]:\"\n",
    "    text_question = \"[Questions]:\"\n",
    "    decompositions = []\n",
    "    evidences = []\n",
    "    for claim_decomp in claim_decomps:\n",
    "        decompositions.append(claim_decomp['claim'])\n",
    "        evidences = evidences + (claim_decomp['evidence'])\n",
    "        \n",
    "    claim = train_data[index]['claim']\n",
    "    for evidence in evidences:\n",
    "      text_evidence += evidence + \". \"\n",
    "    \n",
    "    for decomposition in decompositions:\n",
    "      text_question += decomposition + \" \"\n",
    "    \n",
    "    result = \"[Claim]:\" + claim + text_question + text_evidence\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        result,                      # Sentence to encode.\n",
    "                        add_special_tokens = True,  # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 256,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        truncation=True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "\n",
    "    # Add the encoded sentence to the list.\n",
    "    val_input_ids.append(encoded_dict['input_ids'])\n",
    "\n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    val_attention_masks.append(encoded_dict['attention_mask'])\n",
    "# Convert the lists into tensors.\n",
    "val_input_ids = torch.cat(val_input_ids, dim=0)\n",
    "val_attention_masks = torch.cat(val_attention_masks, dim=0)\n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print(\"Original claim\" , val_data[0]['claim'])\n",
    "# print('Original evidences: ', val_features_final[0])\n",
    "# print('Token IDs:', val_input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "533e75c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T16:58:26.158256Z",
     "iopub.status.busy": "2024-06-11T16:58:26.157699Z",
     "iopub.status.idle": "2024-06-11T16:58:26.176010Z",
     "shell.execute_reply": "2024-06-11T16:58:26.175116Z"
    },
    "papermill": {
     "duration": 0.032241,
     "end_time": "2024-06-11T16:58:26.177845",
     "exception": false,
     "start_time": "2024-06-11T16:58:26.145604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3084\n",
      "3084\n",
      "3084\n"
     ]
    }
   ],
   "source": [
    "train_labels_final = torch.tensor(train_labels_final)\n",
    "val_labels_final = torch.tensor(val_labels_final)\n",
    "\n",
    "num_classes = len(list(set(train_labels)))\n",
    "list(set(train_labels))\n",
    "\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "# train_poincare_tensor = torch.tensor(poincare_embeddings_final,dtype=torch.float)\n",
    "# difficulty_tensor = torch.tensor(difficulty_level_vectors,dtype=torch.float)\n",
    "# Combine the training inputs into a TensorDataset.\n",
    "dataset = TensorDataset(input_ids, attention_masks, train_labels_final)\n",
    "print(len(val_input_ids))\n",
    "print(len(val_attention_masks))\n",
    "print(len(val_labels_final))\n",
    "val_dataset = TensorDataset(val_input_ids, val_attention_masks,val_labels_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e39cdbbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T16:58:26.202673Z",
     "iopub.status.busy": "2024-06-11T16:58:26.202399Z",
     "iopub.status.idle": "2024-06-11T16:58:26.208410Z",
     "shell.execute_reply": "2024-06-11T16:58:26.207585Z"
    },
    "papermill": {
     "duration": 0.021276,
     "end_time": "2024-06-11T16:58:26.210220",
     "exception": false,
     "start_time": "2024-06-11T16:58:26.188944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "batch_size = 16\n",
    "\n",
    "# setting seed !!! is this the right place to do it? !!!\n",
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "            dataset,  # The training samples.\n",
    "            sampler = RandomSampler(dataset , generator=torch.Generator().manual_seed(random_seed)), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(val_dataset),\n",
    "            batch_size = batch_size\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0c77881",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T16:58:26.233473Z",
     "iopub.status.busy": "2024-06-11T16:58:26.233198Z",
     "iopub.status.idle": "2024-06-11T16:58:26.242204Z",
     "shell.execute_reply": "2024-06-11T16:58:26.241370Z"
    },
    "papermill": {
     "duration": 0.022703,
     "end_time": "2024-06-11T16:58:26.244072",
     "exception": false,
     "start_time": "2024-06-11T16:58:26.221369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class MultiClassClassifier(nn.Module):\n",
    "    def __init__(self, bert_model_path, labels_count, hidden_dim=768, mlp_dim=500, extras_dim=100, dropout=0.1, freeze_bert=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = AutoModel.from_pretrained(bert_model_path,output_hidden_states=True,output_attentions=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, mlp_dim),\n",
    "            nn.ReLU(),\n",
    "            # nn.Linear(mlp_dim, mlp_dim),\n",
    "            # # nn.ReLU(),\n",
    "            # # nn.Linear(mlp_dim, mlp_dim),\n",
    "            # nn.ReLU(),\n",
    "            nn.Linear(mlp_dim, labels_count)\n",
    "        )\n",
    "        # self.softmax = nn.LogSoftmax(dim=1)\n",
    "        if freeze_bert:\n",
    "            print(\"Freezing layers\")\n",
    "            for param in self.model.parameters():\n",
    "                param.requires_grad = False\n",
    "    # todo\n",
    "    def forward(self, tokens, masks):\n",
    "#         output = self.model(tokens, attention_mask=masks) # Roberta, BART, Siloed/Deberta \n",
    "        output = self.model(   #flan and t5\n",
    "        input_ids=tokens,\n",
    "        attention_mask=masks,\n",
    "        decoder_input_ids=tokens\n",
    "        )\n",
    "        last_hidden_state = output.last_hidden_state\n",
    "        pooled_output = last_hidden_state.mean(dim=1)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        # concat_output = torch.cat((dropout_output, topic_emb), dim=1)\n",
    "        # concat_output = self.dropout(concat_output)\n",
    "        mlp_output = self.mlp(dropout_output)\n",
    "        # proba = self.sigmoid(mlp_output)\n",
    "        # proba = self.softmax(mlp_output)\n",
    "\n",
    "        return mlp_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc0dfaf0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T16:58:26.267425Z",
     "iopub.status.busy": "2024-06-11T16:58:26.267161Z",
     "iopub.status.idle": "2024-06-11T16:58:30.131548Z",
     "shell.execute_reply": "2024-06-11T16:58:30.130711Z"
    },
    "papermill": {
     "duration": 3.878553,
     "end_time": "2024-06-11T16:58:30.133736",
     "exception": false,
     "start_time": "2024-06-11T16:58:26.255183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dba0b310114442fa88fa7004a2b1c7a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3686bd27cf1488d906b59d9f4a4237a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MultiClassClassifier(\n",
       "  (model): T5Model(\n",
       "    (shared): Embedding(32128, 512)\n",
       "    (encoder): T5Stack(\n",
       "      (embed_tokens): Embedding(32128, 512)\n",
       "      (block): ModuleList(\n",
       "        (0): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (relative_attention_bias): Embedding(32, 8)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseActDense(\n",
       "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): ReLU()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1-5): 5 x T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseActDense(\n",
       "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): ReLU()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layer_norm): T5LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (decoder): T5Stack(\n",
       "      (embed_tokens): Embedding(32128, 512)\n",
       "      (block): ModuleList(\n",
       "        (0): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (relative_attention_bias): Embedding(32, 8)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseActDense(\n",
       "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): ReLU()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1-5): 5 x T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseActDense(\n",
       "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): ReLU()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layer_norm): T5LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=768, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=768, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "#flan and T5: 512 hidden_dim \n",
    "#Roberta: 1024 hidden_dim \n",
    "#Bart: 1024 hidden_dim\n",
    "#Deberta: 768 hidden_dim\n",
    "#Roberta_math: 768 hidden_dim\n",
    "# Loads BertForSequenceClassification, the pretrained BERT model with a single\n",
    "# todo \n",
    "model = MultiClassClassifier(model_name,num_classes, 512,768,140,dropout=0.1,freeze_bert=False)\n",
    "\n",
    "# model.load_state_dict(torch.load(\"model_bert_difficulty_prediction/model_weights\"))\n",
    "\n",
    "# # Tell pytorch to run this model on the GPU.\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d865bc0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T16:58:30.159137Z",
     "iopub.status.busy": "2024-06-11T16:58:30.158656Z",
     "iopub.status.idle": "2024-06-11T16:58:30.169225Z",
     "shell.execute_reply": "2024-06-11T16:58:30.168539Z"
    },
    "papermill": {
     "duration": 0.025299,
     "end_time": "2024-06-11T16:58:30.171184",
     "exception": false,
     "start_time": "2024-06-11T16:58:30.145885",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5,\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )\n",
    "\n",
    "\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs].\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e3b0c97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T16:58:30.196043Z",
     "iopub.status.busy": "2024-06-11T16:58:30.195756Z",
     "iopub.status.idle": "2024-06-11T16:58:30.200361Z",
     "shell.execute_reply": "2024-06-11T16:58:30.199548Z"
    },
    "papermill": {
     "duration": 0.019179,
     "end_time": "2024-06-11T16:58:30.202346",
     "exception": false,
     "start_time": "2024-06-11T16:58:30.183167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c897f758",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T16:58:30.228327Z",
     "iopub.status.busy": "2024-06-11T16:58:30.228066Z",
     "iopub.status.idle": "2024-06-11T16:58:30.232895Z",
     "shell.execute_reply": "2024-06-11T16:58:30.232213Z"
    },
    "papermill": {
     "duration": 0.019453,
     "end_time": "2024-06-11T16:58:30.234820",
     "exception": false,
     "start_time": "2024-06-11T16:58:30.215367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "\n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "506155d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T16:58:30.259670Z",
     "iopub.status.busy": "2024-06-11T16:58:30.259413Z",
     "iopub.status.idle": "2024-06-11T16:58:30.263104Z",
     "shell.execute_reply": "2024-06-11T16:58:30.262393Z"
    },
    "papermill": {
     "duration": 0.018138,
     "end_time": "2024-06-11T16:58:30.265029",
     "exception": false,
     "start_time": "2024-06-11T16:58:30.246891",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2a5046b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T16:58:30.290067Z",
     "iopub.status.busy": "2024-06-11T16:58:30.289780Z",
     "iopub.status.idle": "2024-06-11T16:58:30.300107Z",
     "shell.execute_reply": "2024-06-11T16:58:30.299247Z"
    },
    "papermill": {
     "duration": 0.025133,
     "end_time": "2024-06-11T16:58:30.301984",
     "exception": false,
     "start_time": "2024-06-11T16:58:30.276851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement.\n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d272901",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T16:58:30.326510Z",
     "iopub.status.busy": "2024-06-11T16:58:30.326274Z",
     "iopub.status.idle": "2024-06-11T16:58:30.331044Z",
     "shell.execute_reply": "2024-06-11T16:58:30.330232Z"
    },
    "papermill": {
     "duration": 0.019004,
     "end_time": "2024-06-11T16:58:30.332829",
     "exception": false,
     "start_time": "2024-06-11T16:58:30.313825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# todo \n",
    "\n",
    "for param in model.model.encoder.block[0:5].parameters(): # flan and T5\n",
    "    param.requires_grad=False \n",
    "    \n",
    "# for param in model.model.encoder.layer[0:5].parameters(): # Roberta deberta\n",
    "#     param.requires_grad=False\n",
    "\n",
    "# for param in model.model.encoder.layers[0:5].parameters(): # BART\n",
    "#     param.requires_grad=False\n",
    "    \n",
    "loss_func = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3f4a5ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T16:58:30.357536Z",
     "iopub.status.busy": "2024-06-11T16:58:30.357294Z",
     "iopub.status.idle": "2024-06-11T16:58:30.361124Z",
     "shell.execute_reply": "2024-06-11T16:58:30.360283Z"
    },
    "papermill": {
     "duration": 0.018196,
     "end_time": "2024-06-11T16:58:30.363035",
     "exception": false,
     "start_time": "2024-06-11T16:58:30.344839",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if torch.cuda.is_available():\n",
    "\n",
    "#     # Tell PyTorch to use the GPU.\n",
    "#     device = torch.device(\"cuda\")\n",
    "\n",
    "#     print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "#     print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# # If not...\n",
    "# else:\n",
    "#     print('No GPU available, using the CPU instead.')\n",
    "#     device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82b837bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T16:58:30.388050Z",
     "iopub.status.busy": "2024-06-11T16:58:30.387756Z",
     "iopub.status.idle": "2024-06-11T17:13:37.880093Z",
     "shell.execute_reply": "2024-06-11T17:13:37.879157Z"
    },
    "papermill": {
     "duration": 907.523852,
     "end_time": "2024-06-11T17:13:37.898783",
     "exception": false,
     "start_time": "2024-06-11T16:58:30.374931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 20 ========\n",
      "Training...\n",
      "  Batch    40  of    621.    Elapsed: 0:00:18.\n",
      "  Batch    80  of    621.    Elapsed: 0:00:34.\n",
      "  Batch   120  of    621.    Elapsed: 0:00:51.\n",
      "  Batch   160  of    621.    Elapsed: 0:01:08.\n",
      "  Batch   200  of    621.    Elapsed: 0:01:26.\n",
      "  Batch   240  of    621.    Elapsed: 0:01:43.\n",
      "  Batch   280  of    621.    Elapsed: 0:02:01.\n",
      "  Batch   320  of    621.    Elapsed: 0:02:19.\n",
      "  Batch   360  of    621.    Elapsed: 0:02:36.\n",
      "  Batch   400  of    621.    Elapsed: 0:02:54.\n",
      "  Batch   440  of    621.    Elapsed: 0:03:11.\n",
      "  Batch   480  of    621.    Elapsed: 0:03:29.\n",
      "  Batch   520  of    621.    Elapsed: 0:03:47.\n",
      "  Batch   560  of    621.    Elapsed: 0:04:04.\n",
      "  Batch   600  of    621.    Elapsed: 0:04:22.\n",
      " Train Accuracy: 0.59\n",
      "\n",
      "  Average training loss: 0.90\n",
      "  Training epcoh took: 0:04:31\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.53\n",
      "Validation loss decreased (inf --> 1.071752).  Saving model ...\n",
      "  Validation Loss: 1.07\n",
      "  Validation took: 0:00:30\n",
      "Saving model to /kaggle/working/models/claim_decomp_llm/t5\n",
      "\n",
      "======== Epoch 2 / 20 ========\n",
      "Training...\n",
      "  Batch    40  of    621.    Elapsed: 0:00:18.\n",
      "  Batch    80  of    621.    Elapsed: 0:00:35.\n",
      "  Batch   120  of    621.    Elapsed: 0:00:53.\n",
      "  Batch   160  of    621.    Elapsed: 0:01:10.\n",
      "  Batch   200  of    621.    Elapsed: 0:01:28.\n",
      "  Batch   240  of    621.    Elapsed: 0:01:46.\n",
      "  Batch   280  of    621.    Elapsed: 0:02:03.\n",
      "  Batch   320  of    621.    Elapsed: 0:02:21.\n",
      "  Batch   360  of    621.    Elapsed: 0:02:38.\n",
      "  Batch   400  of    621.    Elapsed: 0:02:56.\n",
      "  Batch   440  of    621.    Elapsed: 0:03:14.\n",
      "  Batch   480  of    621.    Elapsed: 0:03:31.\n",
      "  Batch   520  of    621.    Elapsed: 0:03:49.\n",
      "  Batch   560  of    621.    Elapsed: 0:04:06.\n",
      "  Batch   600  of    621.    Elapsed: 0:04:24.\n",
      " Train Accuracy: 0.62\n",
      "\n",
      "  Average training loss: 0.83\n",
      "  Training epcoh took: 0:04:33\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.53\n",
      "EarlyStopping counter: 1 out of 2\n",
      "  Validation Loss: 1.12\n",
      "  Validation took: 0:00:30\n",
      "Saving model to /kaggle/working/models/claim_decomp_llm/t5\n",
      "\n",
      "======== Epoch 3 / 20 ========\n",
      "Training...\n",
      "  Batch    40  of    621.    Elapsed: 0:00:18.\n",
      "  Batch    80  of    621.    Elapsed: 0:00:35.\n",
      "  Batch   120  of    621.    Elapsed: 0:00:53.\n",
      "  Batch   160  of    621.    Elapsed: 0:01:10.\n",
      "  Batch   200  of    621.    Elapsed: 0:01:28.\n",
      "  Batch   240  of    621.    Elapsed: 0:01:45.\n",
      "  Batch   280  of    621.    Elapsed: 0:02:03.\n",
      "  Batch   320  of    621.    Elapsed: 0:02:21.\n",
      "  Batch   360  of    621.    Elapsed: 0:02:38.\n",
      "  Batch   400  of    621.    Elapsed: 0:02:56.\n",
      "  Batch   440  of    621.    Elapsed: 0:03:13.\n",
      "  Batch   480  of    621.    Elapsed: 0:03:31.\n",
      "  Batch   520  of    621.    Elapsed: 0:03:49.\n",
      "  Batch   560  of    621.    Elapsed: 0:04:06.\n",
      "  Batch   600  of    621.    Elapsed: 0:04:24.\n",
      " Train Accuracy: 0.63\n",
      "\n",
      "  Average training loss: 0.81\n",
      "  Training epcoh took: 0:04:33\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.52\n",
      "EarlyStopping counter: 2 out of 2\n",
      "Early stopping\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:15:07 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# We'll store a number of quantities such as training and validation loss,\n",
    "# validation accuracy, and timings.\n",
    "training_stats = []\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "early_stopping = EarlyStopping(patience=2, verbose=True)\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "\n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "\n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_train_accuracy = 0\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to\n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questimport gensim.downloader as api\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "\n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader.\n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the\n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids\n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels\n",
    "\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        # b_poincare = batch[2].to(device)\n",
    "        # b_difficulty = batch[3].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        # skill_labels = batch[3].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because\n",
    "        # accumulating the gradients is \"convenient while training RNNs\".\n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        probas = model(b_input_ids,b_input_mask)\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value\n",
    "        # from the tensor.\n",
    "        loss = loss_func(probas, b_labels)\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        # scheduler.step()\n",
    "        logits = probas.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        total_train_accuracy += flat_accuracy(logits, label_ids)\n",
    "    avg_train_accuracy = total_train_accuracy / len(train_dataloader)\n",
    "    print(\" Train Accuracy: {0:.2f}\".format(avg_train_accuracy))\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "\n",
    "\n",
    "\n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "\n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables\n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "\n",
    "        # Unpack this training batch from our dataloader.\n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using\n",
    "        # the `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids\n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels\n",
    "        b_input_ids = batch[0].to(device)\n",
    "\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        # b_poincare = batch[2].to(device)\n",
    "        # b_difficulty = batch[3].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        # skill_labels = batch[3].to(device)\n",
    "\n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "\n",
    "          logits = model(b_input_ids,b_input_mask)\n",
    "\n",
    "        # Accumulate the validation loss.\n",
    "        loss = loss_func(logits, b_labels)\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences, and\n",
    "        # accumulate it over all batches.\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    early_stopping(avg_val_loss, model)\n",
    "    if early_stopping.early_stop:\n",
    "      print(\"Early stopping\")\n",
    "      break\n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "\n",
    "#     TODO\n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "    output_dir = '/kaggle/working/models/claim_decomp_llm/t5'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    print(\"Saving model to %s\" % output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "    torch.save(model.state_dict(), os.path.join(output_dir, 'model_weights_t5'))\n",
    "\n",
    "#     !rm -rf \"/content/drive/My Drive/ecir_compnumfacts/model_roberta_large_oracle\"\n",
    "#     !mv model_roberta_large_oracle \"/content/drive/My Drive/ecir_compnumfacts/\"\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "    \n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b1b3fb",
   "metadata": {
    "papermill": {
     "duration": 0.01587,
     "end_time": "2024-06-11T17:13:37.930740",
     "exception": false,
     "start_time": "2024-06-11T17:13:37.914870",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c27a36d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T17:13:37.964425Z",
     "iopub.status.busy": "2024-06-11T17:13:37.963801Z",
     "iopub.status.idle": "2024-06-11T17:13:37.967506Z",
     "shell.execute_reply": "2024-06-11T17:13:37.966698Z"
    },
    "papermill": {
     "duration": 0.022352,
     "end_time": "2024-06-11T17:13:37.969270",
     "exception": false,
     "start_time": "2024-06-11T17:13:37.946918",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from IPython.display import FileLink\n",
    "# FileLink('/kaggle/working/models/luna/model_weights_luna')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b307a2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T17:13:38.002854Z",
     "iopub.status.busy": "2024-06-11T17:13:38.002237Z",
     "iopub.status.idle": "2024-06-11T17:13:38.008075Z",
     "shell.execute_reply": "2024-06-11T17:13:38.007294Z"
    },
    "papermill": {
     "duration": 0.024495,
     "end_time": "2024-06-11T17:13:38.009923",
     "exception": false,
     "start_time": "2024-06-11T17:13:37.985428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'epoch': 1,\n",
       "  'Training Loss': 0.8978558422190748,\n",
       "  'Valid. Loss': 1.0717519821280643,\n",
       "  'Valid. Accur.': 0.5251511226252159,\n",
       "  'Training Time': '0:04:31',\n",
       "  'Validation Time': '0:00:30'},\n",
       " {'epoch': 2,\n",
       "  'Training Loss': 0.8305690482906674,\n",
       "  'Valid. Loss': 1.115199629815749,\n",
       "  'Valid. Accur.': 0.5267702936096719,\n",
       "  'Training Time': '0:04:33',\n",
       "  'Validation Time': '0:00:30'}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f459f058",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T17:13:38.043911Z",
     "iopub.status.busy": "2024-06-11T17:13:38.043450Z",
     "iopub.status.idle": "2024-06-11T17:13:38.047163Z",
     "shell.execute_reply": "2024-06-11T17:13:38.046325Z"
    },
    "papermill": {
     "duration": 0.02277,
     "end_time": "2024-06-11T17:13:38.048950",
     "exception": false,
     "start_time": "2024-06-11T17:13:38.026180",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import json\n",
    "# with open(\"/kaggle/input/quantemp-claims/bm25_top_100_claimdecomp.json\") as f:\n",
    "#   val_b25 = json.load(f)\n",
    "\n",
    "\n",
    "# print(len(val_b25)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "93c4171c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T17:13:38.083186Z",
     "iopub.status.busy": "2024-06-11T17:13:38.082510Z",
     "iopub.status.idle": "2024-06-11T17:13:38.086044Z",
     "shell.execute_reply": "2024-06-11T17:13:38.085248Z"
    },
    "papermill": {
     "duration": 0.022304,
     "end_time": "2024-06-11T17:13:38.087779",
     "exception": false,
     "start_time": "2024-06-11T17:13:38.065475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install rank_bm25"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5120043,
     "sourceId": 8604447,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5120025,
     "sourceId": 8625956,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5162021,
     "sourceId": 8665019,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1053.511613,
   "end_time": "2024-06-11T17:13:39.829907",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-11T16:56:06.318294",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "02d68709d9444a138f5c6be1f003a94c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "063943227b724bcfbb5739eb42f46e5e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0679f14d88ef482f9a765cd9f35e407c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "08a88fcdd63744fc8184372fcc4479d7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e4cfc224b3ee40e1b6e1eccc6400241e",
       "max": 242043056.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a81e3462c2834dd286ed48a1ae6fb105",
       "value": 242043056.0
      }
     },
     "097f6b3d07c2476a922e693747f462a0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "0a5a9d50e4b94e09b69fd4803b4f3038": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "1b55405ff2ce4ca78538ff6acbf55d23": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1cc892858d484000b06807f69a21b2ed": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1fccf9b8852540bdb4a465ac422acea5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "1fd88161ad7c45b6804258c168d3979e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f0a33fa28e3b4355ae05d26abc3e46bd",
       "placeholder": "​",
       "style": "IPY_MODEL_5ad4dda0e22d4ca28d8e2480e71b76c5",
       "value": " 792k/792k [00:00&lt;00:00, 12.1MB/s]"
      }
     },
     "20f7abf87ea14a9994a925a284dbc2f7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2a023455b8694412b4afb38a7fb4840d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_eefdf6460de442ebab4389afd410c715",
       "max": 1389353.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_1fccf9b8852540bdb4a465ac422acea5",
       "value": 1389353.0
      }
     },
     "31b128030dcf461084b76c6e90e23698": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "34e2e273c6ef41dbb3cadf9a6ce81e5d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "35c0b8aa1f1941d6a9ccf26ebe35aea2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_063943227b724bcfbb5739eb42f46e5e",
       "placeholder": "​",
       "style": "IPY_MODEL_097f6b3d07c2476a922e693747f462a0",
       "value": " 242M/242M [00:01&lt;00:00, 202MB/s]"
      }
     },
     "45dbd992d92643828a544581fab35877": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "48d14d865c2840b8929b4d42f6b4e6f0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "49440353ee4c41949eb904def5f5042e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ada3c49381b74f9dbccd7d30d9ea0e2d",
       "placeholder": "​",
       "style": "IPY_MODEL_7afe36b96f6644d7af799d3631feb6d5",
       "value": "tokenizer_config.json: 100%"
      }
     },
     "49704b7b10f0489290aafed0bbddb42f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "4ac4d8e53131410f8a05130015117f8d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5a19d4781b1448ed8964737746cb0ce3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "5ad4dda0e22d4ca28d8e2480e71b76c5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "60b6857430a2463c87fc6067a9e4afa0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "641d1648831b4e8dbbd2c4d0a87835c5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_20f7abf87ea14a9994a925a284dbc2f7",
       "placeholder": "​",
       "style": "IPY_MODEL_5a19d4781b1448ed8964737746cb0ce3",
       "value": " 1.21k/1.21k [00:00&lt;00:00, 103kB/s]"
      }
     },
     "64cac119316d4a1bbbee5a3c3ff45871": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "67addea0074d4f79b5735a7b084156af": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d2e03e145bcd44dd9c14337a56f3ca2f",
       "placeholder": "​",
       "style": "IPY_MODEL_764191ac34554a8ba18fe5d5c8cfb167",
       "value": " 2.32k/2.32k [00:00&lt;00:00, 194kB/s]"
      }
     },
     "6b6d736457cf4b88b024f5010518dca7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7449a043218a4341b36b7c0b79a08ca3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_45dbd992d92643828a544581fab35877",
       "placeholder": "​",
       "style": "IPY_MODEL_0679f14d88ef482f9a765cd9f35e407c",
       "value": "tokenizer.json: 100%"
      }
     },
     "764191ac34554a8ba18fe5d5c8cfb167": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "76858bab8dce49028abda42fc11a5b43": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7afe36b96f6644d7af799d3631feb6d5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "7fdf95e1ef2a4c2f8d0f3b07fec112f4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "81db27d4097b4d61b30055cdd6c343e4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "8c2173875fc2461aae8753813fe95e04": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "90ee1fbf7f174fb791e4acf24d89070c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "956d4b6b64774e24a01157321ac3868a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_76858bab8dce49028abda42fc11a5b43",
       "placeholder": "​",
       "style": "IPY_MODEL_8c2173875fc2461aae8753813fe95e04",
       "value": "model.safetensors: 100%"
      }
     },
     "9c66e34b501f4b72b7cf70198deb7cba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_49440353ee4c41949eb904def5f5042e",
        "IPY_MODEL_b4629777e4b34894a192f66347e9a1c7",
        "IPY_MODEL_67addea0074d4f79b5735a7b084156af"
       ],
       "layout": "IPY_MODEL_34e2e273c6ef41dbb3cadf9a6ce81e5d"
      }
     },
     "9f9891cf9eed44cda20303d48438ad79": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a3686bd27cf1488d906b59d9f4a4237a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_956d4b6b64774e24a01157321ac3868a",
        "IPY_MODEL_08a88fcdd63744fc8184372fcc4479d7",
        "IPY_MODEL_35c0b8aa1f1941d6a9ccf26ebe35aea2"
       ],
       "layout": "IPY_MODEL_7fdf95e1ef2a4c2f8d0f3b07fec112f4"
      }
     },
     "a5455d3b4fcc4c0081a726fe0484eaf9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1cc892858d484000b06807f69a21b2ed",
       "max": 791656.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_81db27d4097b4d61b30055cdd6c343e4",
       "value": 791656.0
      }
     },
     "a5887ea8ee6a48abaa1b5013bdb3920a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1b55405ff2ce4ca78538ff6acbf55d23",
       "placeholder": "​",
       "style": "IPY_MODEL_60b6857430a2463c87fc6067a9e4afa0",
       "value": " 1.39M/1.39M [00:00&lt;00:00, 33.4MB/s]"
      }
     },
     "a81e3462c2834dd286ed48a1ae6fb105": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "aabbd777595342fd9cdf2ee5b2810dd2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_7449a043218a4341b36b7c0b79a08ca3",
        "IPY_MODEL_2a023455b8694412b4afb38a7fb4840d",
        "IPY_MODEL_a5887ea8ee6a48abaa1b5013bdb3920a"
       ],
       "layout": "IPY_MODEL_9f9891cf9eed44cda20303d48438ad79"
      }
     },
     "ada3c49381b74f9dbccd7d30d9ea0e2d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b4629777e4b34894a192f66347e9a1c7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e71b58e87e294ddaa20ae01870f36810",
       "max": 2324.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_49704b7b10f0489290aafed0bbddb42f",
       "value": 2324.0
      }
     },
     "c10ff7ba7ea54218abc7dea1f0a76fa4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_90ee1fbf7f174fb791e4acf24d89070c",
       "max": 1206.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_64cac119316d4a1bbbee5a3c3ff45871",
       "value": 1206.0
      }
     },
     "c2f246aaab814c938798bff3cf5c4383": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f94186cc35474ddeacbd4bd46aadd0a2",
        "IPY_MODEL_a5455d3b4fcc4c0081a726fe0484eaf9",
        "IPY_MODEL_1fd88161ad7c45b6804258c168d3979e"
       ],
       "layout": "IPY_MODEL_6b6d736457cf4b88b024f5010518dca7"
      }
     },
     "c497d8c4886343c9a2f26aad934b1006": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_48d14d865c2840b8929b4d42f6b4e6f0",
       "placeholder": "​",
       "style": "IPY_MODEL_02d68709d9444a138f5c6be1f003a94c",
       "value": "config.json: 100%"
      }
     },
     "d2e03e145bcd44dd9c14337a56f3ca2f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dba0b310114442fa88fa7004a2b1c7a8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c497d8c4886343c9a2f26aad934b1006",
        "IPY_MODEL_c10ff7ba7ea54218abc7dea1f0a76fa4",
        "IPY_MODEL_641d1648831b4e8dbbd2c4d0a87835c5"
       ],
       "layout": "IPY_MODEL_4ac4d8e53131410f8a05130015117f8d"
      }
     },
     "e4cfc224b3ee40e1b6e1eccc6400241e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e71b58e87e294ddaa20ae01870f36810": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "eefdf6460de442ebab4389afd410c715": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f0a33fa28e3b4355ae05d26abc3e46bd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f94186cc35474ddeacbd4bd46aadd0a2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_31b128030dcf461084b76c6e90e23698",
       "placeholder": "​",
       "style": "IPY_MODEL_0a5a9d50e4b94e09b69fd4803b4f3038",
       "value": "spiece.model: 100%"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
